{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a19577-2e7a-4aec-9364-8247c7059d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets import BinChromaDataset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from transformer.models import ContinuousEncoderOnlyWrapper, ContinuousEncoder\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6fea6c-86ba-464d-b216-5691b912fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = '../data/augmented_and_padded_data.npz'\n",
    "dataset = BinChromaDataset(npz_path)\n",
    "\n",
    "train_percentage = 0.9\n",
    "split_idx = int( len(dataset)*train_percentage )\n",
    "\n",
    "train_set = Subset(dataset, range(0,split_idx))\n",
    "test_set = Subset(dataset, range(split_idx, len(dataset)))\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 1000\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a81513d-cc13-43bc-9522-43a5a3f5dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 12\n",
    "tgt_vocab_size = 12\n",
    "d_model = 128\n",
    "num_heads = 16\n",
    "num_layers = 4\n",
    "d_ff = 128\n",
    "max_seq_length = 129\n",
    "dropout = 0.3\n",
    "\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoderModel = ContinuousEncoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "\n",
    "transformer = ContinuousEncoderOnlyWrapper(encoderModel)\n",
    "\n",
    "transformer = transformer.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97921b5-ccb0-488b-9ce1-49a21327c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   0%|                                                                                                                        | 0/600 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   0%|▎                                                       | 3/600 [00:00<02:00,  4.96batch/s, accuracy=tensor(0.0088, device='cuda:0'), loss=1.52e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   1%|▍                                                       | 5/600 [00:00<01:20,  7.37batch/s, accuracy=tensor(0.0133, device='cuda:0'), loss=1.54e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   2%|▊                                                        | 9/600 [00:01<00:56, 10.52batch/s, accuracy=tensor(0.0161, device='cuda:0'), loss=1.6e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   2%|█                                                      | 11/600 [00:01<00:51, 11.52batch/s, accuracy=tensor(0.0197, device='cuda:0'), loss=1.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   2%|█▍                                                     | 15/600 [00:01<00:45, 12.77batch/s, accuracy=tensor(0.0230, device='cuda:0'), loss=1.56e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   3%|█▌                                                     | 17/600 [00:01<00:43, 13.29batch/s, accuracy=tensor(0.0273, device='cuda:0'), loss=1.54e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   4%|█▉                                                     | 21/600 [00:02<00:42, 13.56batch/s, accuracy=tensor(0.0307, device='cuda:0'), loss=1.54e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   4%|██                                                     | 23/600 [00:02<00:41, 13.75batch/s, accuracy=tensor(0.0342, device='cuda:0'), loss=1.54e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   4%|██▍                                                    | 27/600 [00:02<00:41, 13.88batch/s, accuracy=tensor(0.0377, device='cuda:0'), loss=1.54e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   5%|██▋                                                    | 29/600 [00:02<00:40, 14.06batch/s, accuracy=tensor(0.0410, device='cuda:0'), loss=1.53e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   6%|███                                                    | 33/600 [00:02<00:40, 14.14batch/s, accuracy=tensor(0.0439, device='cuda:0'), loss=1.52e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   6%|███▏                                                   | 35/600 [00:03<00:39, 14.25batch/s, accuracy=tensor(0.0461, device='cuda:0'), loss=1.52e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   6%|███▌                                                   | 39/600 [00:03<00:38, 14.43batch/s, accuracy=tensor(0.0480, device='cuda:0'), loss=1.53e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   7%|███▊                                                   | 41/600 [00:03<00:38, 14.37batch/s, accuracy=tensor(0.0499, device='cuda:0'), loss=1.53e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   8%|████▏                                                  | 45/600 [00:03<00:38, 14.38batch/s, accuracy=tensor(0.0516, device='cuda:0'), loss=1.54e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   8%|████▎                                                  | 47/600 [00:03<00:38, 14.44batch/s, accuracy=tensor(0.0535, device='cuda:0'), loss=1.52e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   8%|████▊                                                   | 51/600 [00:04<00:37, 14.55batch/s, accuracy=tensor(0.0552, device='cuda:0'), loss=1.5e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:   9%|████▊                                                  | 53/600 [00:04<00:38, 14.30batch/s, accuracy=tensor(0.0563, device='cuda:0'), loss=1.51e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  10%|█████▎                                                  | 57/600 [00:04<00:37, 14.35batch/s, accuracy=tensor(0.0577, device='cuda:0'), loss=1.5e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  10%|█████▍                                                 | 59/600 [00:04<00:37, 14.33batch/s, accuracy=tensor(0.0586, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  10%|█████▊                                                 | 63/600 [00:04<00:37, 14.26batch/s, accuracy=tensor(0.0595, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  11%|█████▉                                                 | 65/600 [00:05<00:37, 14.33batch/s, accuracy=tensor(0.0602, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  12%|██████▎                                                | 69/600 [00:05<00:37, 14.20batch/s, accuracy=tensor(0.0608, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  12%|██████▌                                                | 71/600 [00:05<00:37, 14.11batch/s, accuracy=tensor(0.0614, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  12%|██████▉                                                | 75/600 [00:05<00:37, 13.92batch/s, accuracy=tensor(0.0620, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  13%|███████                                                | 77/600 [00:06<00:38, 13.74batch/s, accuracy=tensor(0.0626, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  14%|███████▍                                               | 81/600 [00:06<00:39, 13.29batch/s, accuracy=tensor(0.0632, device='cuda:0'), loss=1.49e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  14%|███████▌                                               | 83/600 [00:06<00:38, 13.32batch/s, accuracy=tensor(0.0637, device='cuda:0'), loss=1.48e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  14%|███████▉                                               | 87/600 [00:06<00:38, 13.26batch/s, accuracy=tensor(0.0642, device='cuda:0'), loss=1.48e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  15%|████████▏                                              | 89/600 [00:06<00:39, 12.95batch/s, accuracy=tensor(0.0647, device='cuda:0'), loss=1.47e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  16%|████████▌                                              | 93/600 [00:07<00:39, 12.71batch/s, accuracy=tensor(0.0652, device='cuda:0'), loss=1.47e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  16%|████████▋                                              | 95/600 [00:07<00:39, 12.69batch/s, accuracy=tensor(0.0656, device='cuda:0'), loss=1.46e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  16%|█████████                                              | 99/600 [00:07<00:39, 12.73batch/s, accuracy=tensor(0.0661, device='cuda:0'), loss=1.46e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  17%|█████████                                             | 101/600 [00:07<00:38, 12.81batch/s, accuracy=tensor(0.0665, device='cuda:0'), loss=1.45e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | trn:  18%|█████████▍                                            | 105/600 [00:08<00:38, 12.92batch/s, accuracy=tensor(0.0668, device='cuda:0'), loss=1.45e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n",
      "torch.Size([8, 129, 12])\n",
      "torch.Size([8, 1, 1, 129])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m chords \u001b[38;5;241m=\u001b[39m chords\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m output \u001b[38;5;241m=\u001b[39m transformer(melodies)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# output = transformer(chords) # identity check\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), chords\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/maximos/9C33-6BBD/repos/chameleon_transformer/tests/../transformer/models.py:203\u001b[0m, in \u001b[0;36mContinuousEncoderOnlyWrapper.forward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids):\n\u001b[0;32m--> 203\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_model(input_ids)\n\u001b[1;32m    204\u001b[0m     logits_vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits_vocab_size\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/maximos/9C33-6BBD/repos/chameleon_transformer/tests/../transformer/models.py:188\u001b[0m, in \u001b[0;36mContinuousEncoder.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    185\u001b[0m enc_output \u001b[38;5;241m=\u001b[39m src_embedded\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m enc_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# enc_output = enc_layer(enc_output, None)\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m enc_layer(enc_output, src_mask)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enc_output\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/maximos/9C33-6BBD/repos/chameleon_transformer/tests/../transformer/layers.py:25\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x, mask)\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attn_output))\n\u001b[0;32m---> 25\u001b[0m ff_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(x)\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(ff_output))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/maximos/9C33-6BBD/repos/chameleon_transformer/tests/../transformer/positional_encoding.py:17\u001b[0m, in \u001b[0;36mPositionWiseFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)))\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "# keep best validation loss for saving\n",
    "best_val_loss = np.inf\n",
    "save_dir = '../saved_models/encoderOnly_one_hot/'\n",
    "encoder_path = save_dir + 'encoderOnly_one_hot.pt'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    running_loss = 0\n",
    "    samples_num = 0\n",
    "    running_accuracy = 0\n",
    "    accuracy = 0\n",
    "    with tqdm(train_loader, unit='batch') as tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch} | trn\")\n",
    "        for melodies, chords in tepoch:\n",
    "            melodies = melodies.to(dev)\n",
    "            chords = chords.to(dev)\n",
    "            optimizer.zero_grad()\n",
    "            output = transformer(melodies)\n",
    "            # output = transformer(chords) # identity check\n",
    "            loss = criterion(output.contiguous().view(-1), chords.contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # update loss\n",
    "            samples_num += melodies.shape[0]\n",
    "            running_loss += loss.item()\n",
    "            train_loss = running_loss/samples_num\n",
    "            # accuracy\n",
    "            bin_output = output > 0.5\n",
    "            bin_chords = chords > 0.5\n",
    "            tmp_acc = 0\n",
    "            tmp_count = 0\n",
    "            for b_i in range(bin_output.shape[0]):\n",
    "                for s_i in range(bin_output.shape[1]):\n",
    "                    tmp_count += 1\n",
    "                    tmp_acc += torch.all(bin_output[b_i, s_i, :].eq(bin_chords[b_i, s_i, :]))\n",
    "            running_accuracy += tmp_acc/tmp_count\n",
    "            accuracy = running_accuracy/samples_num\n",
    "            tepoch.set_postfix(loss=train_loss, accuracy=accuracy) # tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy)\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        running_loss = 0\n",
    "        samples_num = 0\n",
    "        running_accuracy = 0\n",
    "        accuracy = 0\n",
    "        print('validation...')\n",
    "        for melodies, chords in test_loader:\n",
    "            melodies = melodies.to(dev)\n",
    "            chords = chords.to(dev)\n",
    "            output = transformer(melodies)\n",
    "            # output = transformer(chords) # identity check\n",
    "            loss = criterion(output.contiguous().view(-1), chords.contiguous().view(-1))\n",
    "            # update loss\n",
    "            samples_num += melodies.shape[0]\n",
    "            running_loss += loss.item()\n",
    "            val_loss = running_loss/samples_num\n",
    "            # accuracy\n",
    "            bin_output = output > 0.5\n",
    "            bin_chords = chords > 0.5\n",
    "            tmp_acc = 0\n",
    "            tmp_count = 0\n",
    "            for b_i in range(bin_output.shape[0]):\n",
    "                for s_i in range(bin_output.shape[1]):\n",
    "                    tmp_count += 1\n",
    "                    tmp_acc += torch.all(bin_output[b_i, s_i, :].eq(bin_chords[b_i, s_i, :]))\n",
    "            running_accuracy += tmp_acc/tmp_count\n",
    "            accuracy = running_accuracy/samples_num\n",
    "        if best_val_loss > val_loss:\n",
    "            print('saving!')\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(transformer.state_dict(), encoder_path)\n",
    "        print(f'validation: accuracy={accuracy}, loss={val_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
