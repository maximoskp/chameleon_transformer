{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9c8a7f3-ddb5-484f-b3e1-fff04bde9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "# from transformer.models import DecoderOnlyModel\n",
    "from data_utils.Datasets import SerializedConcatDataset, PermSerializedConcatDataset, BinarySerializer\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoConfig, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e4fbd6f-5bdf-408d-b6ed-ae338c867e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_id='any_tonality'):\n",
    "    '''\n",
    "    model_id: 'jazz', 'mel_boost', 'perm', 'c_major'\n",
    "    '''\n",
    "    if model_id == 'c_major':\n",
    "        with open('serializer_cmaj_nottingham.pkl', 'rb') as inp:\n",
    "            binser = pickle.load(inp)\n",
    "    else:\n",
    "        with open('serializer_jazz.pkl', 'rb') as inp:\n",
    "            binser = pickle.load(inp)\n",
    "    \n",
    "    # define model\n",
    "    vocab_size = binser.vocab_size\n",
    "    d_model = 256\n",
    "    num_heads = 4\n",
    "    num_layers = 4\n",
    "    max_seq_length = binser.max_seq_length\n",
    "    d_ff = 256\n",
    "    dropout = 0.3\n",
    "    \n",
    "    # dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\n",
    "        \"gpt2\",\n",
    "        vocab_size=vocab_size,\n",
    "        n_positions=max_seq_length,\n",
    "        n_layer=num_layers,\n",
    "        n_head=num_heads,\n",
    "        pad_token_id=binser.padding,\n",
    "        bos_token_id=binser.padding,\n",
    "        eos_token_id=binser.padding,\n",
    "        n_embd=d_ff\n",
    "    )\n",
    "    transformer = GPT2LMHeadModel(config).to(dev)\n",
    "    transformer = transformer.to(dev)\n",
    "\n",
    "    if model_id == 'c_major':\n",
    "        saved_model_path = '../saved_models/melboost_cmaj_nottingham_GPT2/melboost_cmaj_nottingham_GPT2.pt'\n",
    "    elif model_id == 'perm':\n",
    "        saved_model_path = '../saved_models/perm_jazz_GPT2/perm_jazz_GPT2.pt'\n",
    "    elif model_id == 'mel_boost':\n",
    "        saved_model_path = '../saved_models/melboost_jazz_GPT2/melboost_jazz_GPT2.pt'\n",
    "    else:\n",
    "        saved_model_path = '../saved_models/jazz_GPT2/jazz_GPT2.pt'\n",
    "    transformer.load_state_dict(torch.load(saved_model_path), strict=False)\n",
    "    \n",
    "    transformer.eval()\n",
    "    return transformer\n",
    "# end load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bc1804f-0207-4df3-ae3e-23dbb6ca946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_melody_pcps_with_model_id(melody_pcps, model_id):\n",
    "    model = load_model(model_id)\n",
    "    binser2 = BinarySerializer()\n",
    "    # melody_pcps to serialized\n",
    "    x_mel, _ = binser2.sequence_serialization( melody_pcps, np.array([]) )\n",
    "    # x_mel has 'end harmonizing' at the end - remove it\n",
    "    x_mel = x_mel[:-1]\n",
    "    # run model\n",
    "    # dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    inp = torch.from_numpy( np.expand_dims(x_mel, axis=0)).to(dev)\n",
    "    output = model.generate(inputs=inp, eos_token_id=29, max_new_tokens=300)\n",
    "    # print('x_mel: ', inp)\n",
    "    # print('output: ', output)\n",
    "    # back to binary\n",
    "    bin_all = binser2.indexes2binary( list(output)[0] )\n",
    "    # make sure length of melody and chords are equal\n",
    "    c = bin_all['chords']\n",
    "    m = bin_all['melody']\n",
    "    if c.shape[1] > m.shape[1]:\n",
    "        c = c[:, :m.shame[1]]\n",
    "    elif c.shape[1] < m.shape[1]:\n",
    "        c = np.c_[c, np.zeros( (12, m.shape[1] - c.shape[1] ) )]\n",
    "    return c, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53670bdd-f03d-4631-a179-df9cb88eec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5328, 129, 12)\n",
      "(129, 12)\n",
      "x_mel:  tensor([[ 1,  2,  4, 13,  2,  2,  3,  4, 13,  2,  2,  3, 11,  2,  3, 13,  2, 11,\n",
      "          2,  3, 13,  2,  4, 13,  2,  2,  3,  4, 13,  2, 11,  2,  3,  8,  2,  8,\n",
      "          2,  5,  8,  2,  7,  2,  5,  8,  2,  7,  2,  7,  2,  3,  5,  2,  7,  2,\n",
      "          3,  5,  2,  5,  8,  2,  7,  2,  5,  8,  2,  7,  2,  3, 12,  2, 11,  2,\n",
      "          4, 13,  2,  2,  3,  4, 13,  2,  2,  3, 11,  2,  3, 13,  2, 11,  2,  3,\n",
      "         13,  2,  4, 13,  2,  2,  3,  4, 13,  2, 11,  2,  3, 11,  2, 11,  2, 13,\n",
      "          2, 11,  2,  9,  2,  8,  2, 11,  2,  9,  2,  6,  8,  2,  4, 13,  2,  2,\n",
      "          3,  4, 13,  2,  8,  2,  3,  4,  2,  4,  2, 15]])\n",
      "output:  tensor([[ 1,  2,  4, 13,  2,  2,  3,  4, 13,  2,  2,  3, 11,  2,  3, 13,  2, 11,\n",
      "          2,  3, 13,  2,  4, 13,  2,  2,  3,  4, 13,  2, 11,  2,  3,  8,  2,  8,\n",
      "          2,  5,  8,  2,  7,  2,  5,  8,  2,  7,  2,  7,  2,  3,  5,  2,  7,  2,\n",
      "          3,  5,  2,  5,  8,  2,  7,  2,  5,  8,  2,  7,  2,  3, 12,  2, 11,  2,\n",
      "          4, 13,  2,  2,  3,  4, 13,  2,  2,  3, 11,  2,  3, 13,  2, 11,  2,  3,\n",
      "         13,  2,  4, 13,  2,  2,  3,  4, 13,  2, 11,  2,  3, 11,  2, 11,  2, 13,\n",
      "          2, 11,  2,  9,  2,  8,  2, 11,  2,  9,  2,  6,  8,  2,  4, 13,  2,  2,\n",
      "          3,  4, 13,  2,  8,  2,  3,  4,  2,  4,  2, 15, 16, 18, 22, 25, 27, 16,\n",
      "         18, 22, 25, 27, 16, 18, 20, 23, 27, 16, 20, 23, 25, 16, 17, 18, 22, 25,\n",
      "         16, 17, 18, 21, 23, 25, 27, 16, 20, 22, 25, 16, 17, 18, 19, 22, 25, 27,\n",
      "         16, 18, 20, 23, 27, 16, 20, 23, 25, 16, 17, 18, 22, 25, 16, 17, 18, 22,\n",
      "         25, 27, 16, 18, 20, 23, 27, 16, 20, 23, 25, 16, 17, 18, 22, 25, 16, 17,\n",
      "         19, 22, 24, 28, 16, 19, 22, 24, 28, 16, 21, 24, 28, 16, 17, 19, 22, 24,\n",
      "         27, 16, 21, 24, 27, 16, 17, 21, 22, 26, 16, 17, 19, 22, 26, 16, 17, 19,\n",
      "         22, 24, 27, 16, 21, 24, 27, 16, 17, 21, 22, 26, 16, 17, 20, 23, 25, 16,\n",
      "         17, 18, 22, 25, 27, 16, 18, 22, 25, 27, 16, 18, 20, 23, 27, 16, 20, 23,\n",
      "         25, 16, 17, 18, 22, 25, 16, 17, 18, 21, 23, 25, 27, 16, 20, 22, 25, 16,\n",
      "         17, 18, 19, 22, 25, 27, 16, 18, 20, 23, 27, 16, 20, 23, 25, 16, 17, 18,\n",
      "         22, 25, 16, 17, 18, 21, 23, 25, 27, 16, 20, 22, 25, 16, 17, 18, 19, 22,\n",
      "         25, 27, 16, 18, 20, 23, 27, 16, 20, 23, 25, 16, 17, 18, 22, 25, 16, 17,\n",
      "         18, 21, 23, 25, 27, 16, 20, 22, 25, 16, 17, 18, 19, 22, 25, 27, 16, 18,\n",
      "         20, 23, 27, 16, 20, 23, 25, 16, 17, 18, 22, 25, 16, 17, 18, 21, 23, 25,\n",
      "         27, 16, 20, 22, 25, 16, 17, 18, 19, 22, 25, 27, 16, 18, 20, 23, 27, 16,\n",
      "         20, 23, 25, 16, 17, 18, 22, 25, 16, 17, 18, 22, 25, 27, 16, 18, 20, 23,\n",
      "         27, 16, 20, 23, 25, 16]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# load data\n",
    "npz_path = '../data/augmented_and_padded_data.npz'\n",
    "data = np.load(npz_path)\n",
    "melody_pcps = data['melody_pcps'].astype('float32')\n",
    "print(melody_pcps.shape)\n",
    "melody_pcp = melody_pcps[0]\n",
    "# melody_pcp = np.roll(melody_pcps[0],[0,1])\n",
    "print(melody_pcp.shape)\n",
    "\n",
    "# binser2 = BinarySerializer(left_padding=False)\n",
    "# x, _ = binser2.sequence_serialization( melody_pcp, np.array([]) )\n",
    "# # the last element is 'st'\n",
    "# print(x.shape)\n",
    "# with np.printoptions(threshold=np.inf):\n",
    "#     print(x)\n",
    "# print(mask.shape)\n",
    "\n",
    "# model_id = 'c_major'\n",
    "model_id = 'any_tonality'\n",
    "\n",
    "c, m = harmonize_melody_pcps_with_model_id(melody_pcp, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1edac08a-b203-4623-8146-a857ce6438e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "output:  [[0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(threshold=np.inf):\n",
    "    print('input: ', m)\n",
    "    print('output: ', c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
