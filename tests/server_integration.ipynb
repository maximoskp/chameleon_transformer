{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9c8a7f3-ddb5-484f-b3e1-fff04bde9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "# from transformer.models import DecoderOnlyModel\n",
    "from data_utils.Datasets import SerializedConcatDataset, PermSerializedConcatDataset, BinarySerializer\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoConfig, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e4fbd6f-5bdf-408d-b6ed-ae338c867e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_id='any_tonality'):\n",
    "    '''\n",
    "    model_id: 'any_tonality' or 'c_major'\n",
    "    '''\n",
    "    with open('serializer.pkl', 'rb') as inp:\n",
    "        binser = pickle.load(inp)\n",
    "    \n",
    "    # define model\n",
    "    vocab_size = binser.vocab_size\n",
    "    d_model = 256\n",
    "    if model_id == 'c_major':\n",
    "        num_heads = 2\n",
    "        num_layers = 2\n",
    "        max_seq_length = 3795\n",
    "    else:\n",
    "        num_heads = 4\n",
    "        num_layers = 4\n",
    "        max_seq_length = 1063\n",
    "    d_ff = 256\n",
    "    dropout = 0.3\n",
    "    \n",
    "    # dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\n",
    "        \"gpt2\",\n",
    "        vocab_size=vocab_size,\n",
    "        n_positions=max_seq_length,\n",
    "        n_layer=num_layers,\n",
    "        n_head=num_heads,\n",
    "        pad_token_id=binser.padding,\n",
    "        bos_token_id=binser.padding,\n",
    "        eos_token_id=binser.padding,\n",
    "        n_embd=d_ff\n",
    "    )\n",
    "    transformer = GPT2LMHeadModel(config).to(dev)\n",
    "    transformer = transformer.to(dev)\n",
    "\n",
    "    if model_id == 'c_major':\n",
    "        saved_model_path = '../saved_models/melboost_cmaj_GPT2_serialized/melboost_cmaj_GPT2_serialized.pt'\n",
    "    else:\n",
    "        saved_model_path = '../saved_models/melboost_GPT2_serialized/melboost_GPT2_serialized.pt'\n",
    "    transformer.load_state_dict(torch.load(saved_model_path), strict=False)\n",
    "    \n",
    "    transformer.eval()\n",
    "    return transformer\n",
    "# end load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bc1804f-0207-4df3-ae3e-23dbb6ca946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_melody_pcps_with_model_id(melody_pcps, model_id):\n",
    "    model = load_model(model_id)\n",
    "    binser2 = BinarySerializer()\n",
    "    # melody_pcps to serialized\n",
    "    x_mel = binser2.sequence_serialization( melody_pcps, np.array([]) )\n",
    "    print('x_mel:', x_mel)\n",
    "    # x_mel has 'end harmonizing' at the end - remove it\n",
    "    x_mel = x_mel[:-1]\n",
    "    # run model\n",
    "    # dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dev = torch.device(\"cpu\")\n",
    "    inp = torch.from_numpy( np.expand_dims(x_mel, axis=0)).to(dev)\n",
    "    output = model(inp, attention_mask=inp != 0, output_attentions=True)\n",
    "    prediction = output.logits.argmax(dim=2, keepdim=True).squeeze()\n",
    "    z = prediction.cpu().numpy()\n",
    "    # back to binary\n",
    "    bin_all = binser2.indexes2binary( z )\n",
    "    # make sure length of melody and chords are equal\n",
    "    c = bin_all['chords']\n",
    "    m = bin_all['melody']\n",
    "    if c.shape[1] > m.shape[1]:\n",
    "        c = c[:, :m.shame[1]]\n",
    "    elif c.shape[1] < m.shape[1]:\n",
    "        c = np.c_[c, np.zeros( (12, m.shape[1] - c.shape[1] ) )]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53670bdd-f03d-4631-a179-df9cb88eec9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model_id = 'c_major'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124many_tonality\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m c \u001b[38;5;241m=\u001b[39m harmonize_melody_pcps_with_model_id(melody_pcps, model_id)\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mharmonize_melody_pcps_with_model_id\u001b[0;34m(melody_pcps, model_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mharmonize_melody_pcps_with_model_id\u001b[39m(melody_pcps, model_id):\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model(model_id)\n\u001b[1;32m      3\u001b[0m     binser2 \u001b[38;5;241m=\u001b[39m BinarySerializer()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# melody_pcps to serialized\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 43\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_id)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     saved_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../saved_models/melboost_GPT2_serialized/melboost_GPT2_serialized.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 43\u001b[0m transformer\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(saved_model_path), strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m transformer\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformer\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/serialization.py:1026\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1025\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1026\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1027\u001b[0m                      map_location,\n\u001b[1;32m   1028\u001b[0m                      pickle_module,\n\u001b[1;32m   1029\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1030\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1034\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/serialization.py:1438\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1437\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1438\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1440\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1441\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1443\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/serialization.py:1408\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1408\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/serialization.py:1382\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1381\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1382\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1383\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1384\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1387\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/serialization.py:391\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 391\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcuda(device)\n",
      "File \u001b[0;32m~/miniconda/envs/torch/lib/python3.11/site-packages/torch/_utils.py:118\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[0;32m--> 118\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# load data\n",
    "npz_path = '../data/augmented_and_padded_data.npz'\n",
    "data = np.load(npz_path)\n",
    "melody_pcps = data['melody_pcps'].astype('float32')\n",
    "\n",
    "# model_id = 'c_major'\n",
    "model_id = 'any_tonality'\n",
    "\n",
    "c = harmonize_melody_pcps_with_model_id(melody_pcps, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edac08a-b203-4623-8146-a857ce6438e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(threshold=np.inf):\n",
    "    print('input: ', melody_pcps)\n",
    "    print('output: ', c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
